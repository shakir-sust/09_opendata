---
title: "Feature Engineering"
format: html
---

# Introduction  
The practice of finding better representations of predictors (i.e., features) to improve predictive performance is referred to as “feature engineering.”

In other words, sometimes the predictor variables at hand are not in themselves the best representation to explain a predicted variable.  

In these cases, we can use these original predictor variables to derive new, more informative secondary variables. 

[Note: the purpose of feather engineering is to create new predictor variables (aka features) that we already have because the predictors that we already have in hand may not be the best representations of what we are trying to model]


# Learning objectives  
Our learning objectives are to:  

  - Apply feature engineering concepts to "Daymet" daily weather data [that we obtained and processed]   
  - Export the feature-engineered data set for further use   

# Setup  
```{r}
#| message: false
#| warning: false

#install.packages("ggridges")

#library(ggridges)
library(tidyverse)
```

```{r}

fieldweather <- read_csv("../data/fieldweatherdata.csv")

fieldweather

```

Our data set contains **254,770** rows (= 698 site-years x 365 days/site-year) comprised by **698** site-years and **365** days/site-year worth of weather data.  

# EDA [with "summary()" function] 

[ Very important note: 

We always need to do EDA to check that the data at hand **actually makes sense**. For example, if there were any negative value in "prcp_mm_day", it would indicate that something is wrong (e.g., type, difference in NA coding -- for example, some open source databases code NAs as -9999; in that case we need to change all -9999 values as NAs) because precipitation cannot be negative.

EDA also helps us to understand the data distribution of all predictors. For instance, if a dataframe/ variable has data that is normally distributed, the mean and median would be very similar/ pretty close to each other. If we have a right-skewed distribution, the median > mean (because mean is sensitive to outliers, but median is NOT sensitive to outliers). f we have a left-skewed distribution, the median < mean. In this way, we can get a sense of data distribution of each predictors by looking at the EDA results. 

TLDR; EDA with summary() always helps to identify any error in the dataset. 

]

```{r}

summary(fieldweather)

```




Let's create some density plots to explore the weather data distributions.  

[Important note: It is always a good practice to create density plot to understand the distribution of the data]


```{r}

fieldweather %>%
  pivot_longer(cols = dayl_s:vp_pa) %>% #we are doing pivot_longer just for plotting #to create 'long' form from wide 'form' #we will have 43*16 = 688 columns that we pivoted into 'long' form
  ggplot(aes(x = value)) + #we feed the "value" from previous data right into "ggplot()"
  geom_density() +
  facet_wrap(.~name, scales = "free") #To facet by "name" #scales = "free": this argument auto-adjust the scales (on x-axis and y-axis) depending on the plot  #we facet by "name" column

```

# Feature engineering  

Let's take another look at the data at hand:  

```{r}

fieldweather

```

Currently, we have weather data for each site-year at a **daily** time interval.  

Although this level of temporal resolution is great, plant outputs like yield or quality rarely respond to weather events that occur in one given day (unless it is a severe event like flooding or tornado).  

Rather, plants respond to the cumulative effects of weather across many days. 

How could we use this understanding to create new features from the current ones?    

One option is "Growing degree days" based on temperature data.

## Quiz - go to eLC  

How could we use this understanding to create new features from the current ones?  (new features = new predictors)

There are **two components** that we can consider when feature engineering weather data:  

1. Summarizing time **window size**  
  - Weekly  
  - Monthly  
  - Every 2 months  
  - (Entire) Growing season  
  - Based on crop growth stages [if we have planting and harvest date]
  - Other? [growing degree days based on temperature data]
  
2. Summarizing **function**  
  - Mean  
  - Median  
  - Minimum  
  - Maximum  
  - Standard deviation  

In the next section, let's use the following:  
  - Summarizing time window size: **monthly**  
  - Summarizing function: **mean** or **sum**  

## Quiz - go to eLC  

Let's take a look into date formats in R:  
https://www.r-bloggers.com/2013/08/date-formats-in-r/ 

A great package to work with dates and times in R is called **lubridate**, see vignette here: https://lubridate.tidyverse.org/index.html  

Next, let's create a column containing the month information.  

```{r fe_month}

fe_month <- fieldweather %>%
  # Selecting needed variables
  dplyr::select(year, site, lat, lon,
                strength_gtex,
                yday,
                dayl.s = dayl_s, #to rename variable name from "dayl_s" to dayl.s
                prcp.mm = prcp_mm_day, #to rename variable name to "prcp.mm"
                srad.wm2 = srad_w_m_2,#to rename variable name to "srad.wm2"
                tmax.c = tmax_deg_c, #to rename variable name to "tmax.c"
                tmin.c = tmin_deg_c,#to rename variable name to "tmin.c"
                vp.pa = vp_pa #to rename variable name to "vp.pa"
                ) %>%
  # Creating a date class variable  
  mutate(date_chr = paste0(year, "/", yday)) %>% #The format of "date_chr" is "chr", we will change it to "date" format when we use "as.Date()" function in the next line
  mutate(date = as.Date(date_chr, "%Y/%j")) %>% #"%Y/%j" because we used "/" in paste0(year, "/", yday) at the previous line #If instead of using "/" we used "-" in the previous line as "mutate(date_chr = paste0(year, "-", yday))", we would simply use "mutate(date = as.Date(date_chr, "%Y-%j"))" in the current line 
  #Date-related documentation details: https://www.r-bloggers.com/2013/08/date-formats-in-r/
  # Extracting month from date  
  mutate(month = month(date)) %>% #we use month() function to extract only the numerical number of the month as "dbl" format (number of the month e.g., "1" for "January" etc) from an object that has the year/month/date data (i.e., "date" object that we created in the previous line) #the 1st "month" inside mutate is to name the new column, the 2nd "month" after = sign is the month() function from lubridate package #month is in "dbl" (double) format
  mutate(month_abb = month(date, label = T)) #To get abbreviated month name e.g., Jan, Feb, Mar,...,Dec #month_abb is in "ord" (ordinal) format


fe_month

```

Now, let's summarize daily weather variables based on month.  

```{r fe_month_sum}

fe_month_sum <- fe_month %>%
  group_by(year, site, month_abb, strength_gtex) %>% #If we do a summarise() after group_by(), any column that's not in the group_by() is gone, so we need to include "strength_gtex" in the group_by() to include it in the data frame because "strength_gtex" is our response variable so we must keep it in the data frame 
  #Because we are gonna be applying a "summarize()" function to different columns, we are gonna use a function called "across()" 
  summarise(across(.cols = c(dayl.s,
                             srad.wm2,
                             tmax.c,
                             tmin.c,
                             vp.pa),
                   .fns = mean, #do not indicate the actual function "mean()", just use the word "mean"
                   .names = "mean_{.col}"), #specifying the weather variables that we want their mean as new column variables #1st across() is applying the "mean" function (to summarize "mean")
            across(.cols = prcp.mm,
                   .fns = sum,
                   .names = "sum_{.col}"
                   ) #specifying the weather variable (prcp.mm) that we want its sum as new column variable #2nd across() is summarizing sum #2nd across() is applying the "sum" function (to summarize "sum")
            ) %>%
  ungroup() #To convert from "group" to "tibble"


fe_month_sum

#8,376 rows = 698 site-years x 12 months (of a year)

```

8,376 rows because 698 site-years x 12 months.  

Let's check tmax.c and prcp.mm for the first site-year and month. 

[Note: the following code chunk is for double checking to make sure that we did everything okay the way we intended] 

```{r}

fe_month %>%
  filter(year == 1980 & 
           site == "Altus, OK" &
           month_abb == "Jan") %>%
  summarise(tmax.c = mean(tmax.c),
            prcp.mm = sum(prcp.mm))


```

Now, what if we wanted to have month as part of the column name instead?  

```{r fe_month_sum_wide}

fe_month_sum_wide <- fe_month_sum %>%
  pivot_longer(cols = mean_dayl.s:sum_prcp.mm) %>%
  mutate(varname = paste0(name, "_", month_abb)) %>% #To create a new column "varname" which contains the combination of "name" and "month_abb"
  dplyr::select(-name, -month_abb) %>% #To remove "name" and "month_abb" columns so that we do not get any "NA" when we pivot_wider()
  pivot_wider(names_from = varname,
              values_from = value) %>%
  # Rounding to one decimal point
  mutate(across(c(3:75), ~round(., 1) )) #"mutate(across(c(3:75), ~round(., 1) ))": To round all columns except year and site to 1 decimal place #across() function has 2 arguments: the 1st argument "c(3:75)" is to select the position of columns on which the rounding will be applied; the 2nd argument "~round(., 1) " is to indicate the decimal place to be rounded for; "." is used to represent all those selected columns i.e., we are saying that round each of the selected columns to 1 decimal places #alternatively: mutate(across(c(3:ncol(.)), ~round(., 1) )) #alternatively: mutate(across(3:75), ~round(., 1) )); mutate(across(3:ncol(.), ~round(., 1) )); mutate(across(c(strength_gtex:sum_prcp.mm_Dec), ~round(., 1) ))

fe_month_sum_wide  

```
Notice how we are back at **698** rows.  

For each site-year, we have one piece of weather information for each of the weather variables (as opposed to the original Daymet data that had 365 rows per site-year).  

Let's explore our newly engineered variables.  

# EDA round 2  
Let's make a ridge plot to visualize the distribution of one variable over months.  

```{r, message=FALSE, warning=FALSE}

#install.packages("ggridges")
library(ggridges) #really powerful package to plot distributions e.g., density plot

ggplot(data = fe_month_sum,
       aes(x = mean_tmax.c,
           y = month_abb,
           fill = stat(x) #fill = stat(x): specific to "ggridges"
           )
       ) +
  geom_density_ridges_gradient(scale = 3,
                               rel_min_height = 0.01) + #"the 2nd argument is"rel_min_height = 0.01": to cut down the tails of the distribution
  scale_fill_viridis_c(option = "C") + #"viridis"scale_fill_viridis_c()": color-blind-friendly color scale #argument (option = "C") to change the color to magma option; "option = " varies from A to F
  theme(legend.position = "none") #"theme(legend.position = "none")": to remove legends

```

Now let's do that for all variables [ we will automate using map2() to conduct iteration ]

```{r}

finalplots <- fe_month_sum %>%
  pivot_longer(mean_dayl.s:sum_prcp.mm) %>%
  group_by(name) %>%
  nest() %>% #combo of "group_by()" and "nest()"
  mutate(plot = map2(data, name, #map2() takes 2 arguments: the 1st argument becomes .x, the 2nd argument becomes .y #we must use map2() with a mutate() at first for iteration #"map2(data, name" : we want to iterate over "name" for "data"
                     ~ ggplot( data = .x, # .x represent "data" in the map2() function, so we need to use data = .x [= "data" from map2() ] to feed the "data" from map2() function as the data of ggplot() #.x is the iterating column of map2() that is a place holder for the 1st argument of map2()
       aes(x = value,
           y = month_abb,
           fill = stat(x)
           )
       ) +
  geom_density_ridges_gradient(scale = 3,
                               rel_min_height = 0.01) + 
  scale_fill_viridis_c(option = "C") + 
  theme(legend.position = "none") +
  labs(x = .y) #to rename the x-axis as the variable name # .y is the placeholder for "name" i.e., variable name in map2() function
                     )) 
  
finalplots

```

```{r}
#| message: false

finalplots$plot #$plot to print all the ggplots for each variable

```

# Exporting  
```{r}

write_csv(fe_month_sum_wide,
          "../data/weather_monthsum.csv")

```

# Summary  
In this exercise, we:  
  - Imported the original **7** weather variables from Daymet  
  - Feature engineered a total of **72** secondary variables by applying a summarizing window size of **month** and a summarizing function of **mean or sum**.  
  - Explored the data distribution of the new variables.  
  - Exported to file to be used in subsequent exercises.




  
