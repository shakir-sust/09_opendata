---
title: "Feature Engineering"
format: html
---

# Introduction  
The practice of finding better representations of predictors (i.e., features) to improve predictive performance is referred to as “feature engineering.”

In other words, sometimes the predictor variables at hand are not in themselves the best representation to explain a predicted variable.  

In these cases, we can use these original predictor variables to derive new, more informative secondary variables.  


# Learning objectives  
Our learning objectives are to:  

  - Apply feature engineering concepts to Daymet daily weather data    
  - Export the feature-engineered data set for further use   

# Setup  
```{r}
#| message: false
#| warning: false

#install.packages("ggridges")

#library(ggridges)
library(tidyverse)
```

```{r}

fieldweather <- read_csv("../data/fieldweatherdata.csv")

fieldweather

```

Our data set contains **254,770** rows (= 698 site-years x 365 days/site-year) comprised by **698** site-years and **365** days/site-year worth of weather data.  

# EDA  

```{r}

summary(fieldweather)

```

If a dataframe/ variable has data that is normally distributed, the mean and median would be very similar/ pretty close to each other.  

If we have a right-skewed distribution, the median > mean (because mean is sensitive to outliers, but median is NOT sensitive to outliers)  


Let's create some density plots to explore the weather data distributions.  

```{r}

fieldweather %>%
  pivot_longer(cols = dayl_s:vp_pa) %>% #we are doing pivot_longer just for plotting #to create 'long' form from wide 'form' #we will have 43*16 = 688 columns that we pivoted into 'long' form
  ggplot(aes(x = value)) + #we feed the "value" from previous data right into "ggplot()"
  geom_density() +
  facet_wrap(.~name, scales = "free") #To facet by "name" #scales = "free": this argument auto-adjust the scales (on x-axis and y-axis) depending on the plot  #we facet by "name" column

```

# Feature engineering  

Let's take another look at the data at hand:  

```{r}

fieldweather

```

Currently, we have weather data for each site-year at a **daily** time interval.  

Although this level of temporal resolution is great, plant outputs like yield or quality rarely respond to weather events that occur in one given day (unless it is a severe event like flooding or tornado).  

Rather, plants respond to the cumulative effects of weather across many days. 

How could we use this understanding to create new features from the current ones?    

One option is "Growing degree days" based on temperature data.

## Quiz - go to eLC  

How could we use this understanding to create new features from the current ones?  

There are **two components** that we can consider when feature engineering weather data:  

1. Summarizing time **window size**  
  - Weekly  
  - Monthly  
  - Every 2 months  
  - (Entire) Growing season  
  - Based on crop growth stages  
  - Other?  
  
2. Summarizing **function**  
  - Mean  
  - Median  
  - Minimum  
  - Maximum  
  - Standard deviation  

In the next section, let's use the following:  
  - Summarizing time window size: **monthly**  
  - Summarizing function: **mean** or **sum**  

## Quiz - go to eLC  

Let's take a look into date formats in R:  
https://www.r-bloggers.com/2013/08/date-formats-in-r/ 

A great package to work with dates and times in R is called **lubridate**, see vignette here: https://lubridate.tidyverse.org/index.html  

Next, let's create a column containing the month information.  

```{r fe_month}

fe_month <- fieldweather %>%
  # Selecting needed variables
  dplyr::select(year, site, lat, lon,
                strength_gtex,
                yday,
                dayl.s = dayl_s, #to rename variable name from "dayl_s" to dayl.s
                prcp.mm = prcp_mm_day, #to rename variable name to "prcp.mm"
                srad.wm2 = srad_w_m_2,#to rename variable name to "srad.wm2"
                tmax.c = tmax_deg_c, #to rename variable name to "tmax.c"
                tmin.c = tmin_deg_c,#to rename variable name to "tmin.c"
                vp.pa = vp_pa #to rename variable name to "vp.pa"
                ) %>%
  # Creating a date class variable  
  mutate(date_chr = paste0(year, "/", yday)) %>% #The format of "date_chr" is "chr", we will change it to "date" format in the next line
  mutate(date = as.Date(date_chr, "%Y/%j")) %>% #"%Y/%j" because we used "/" in paste0(year, "/", yday) at the previous line #Date-related documnetation details: https://www.r-bloggers.com/2013/08/date-formats-in-r/
  # Extracting month from date  
  mutate(month = month(date)) %>% #the 1st "month" inside mutate is to name the new column, the 2nd "month" after = sign is the month() function from lubridate package #month is in "dbl" (double) format
  mutate(month_abb = month(date, label = T)) #To get abbreviated month name e.g., Jan, Feb, Mar,...,Dec #month_abb is in "ord" (ordinal) format


fe_month

```

Now, let's summarize daily weather variables based on month.  

```{r fe_month_sum}

fe_month_sum <- fe_month %>%
  group_by(year, site, month_abb, strength_gtex) %>%
  summarise(across(.cols = c(dayl.s,
                             srad.wm2,
                             tmax.c,
                             tmin.c,
                             vp.pa),
                   .fns = mean,
                   .names = "mean_{.col}"), #1st across() is summarizing mean
            across(.cols = prcp.mm,
                   .fns = sum,
                   .names = "sum_{.col}"
                   ) #2nd across() is summarizing sum
            ) %>%
  ungroup() #To convert from "group" to "tibble"


fe_month_sum

#8,376 rows = 698 site-years x 12 months (of a year)

```

8,376 rows because 698 site-years x 12 months.  

Let's check tmax.c and prcp.mm for the first site-year and month.  

```{r}

fe_month %>%
  filter(year == 1980 & 
           site == "Altus, OK" &
           month_abb == "Jan") %>%
  summarise(tmax.c = mean(tmax.c),
            prcp.mm = sum(prcp.mm))

```

Now, what if we wanted to have month as part of the column name instead?  

```{r fe_month_sum_wide}

fe_month_sum_wide <- fe_month_sum %>%
  pivot_longer(cols = mean_dayl.s:sum_prcp.mm) %>%
  mutate(varname = paste0(name, "_", month_abb)) %>% #To create a new column "varname" which contains the combination of "name" and "month_abb"
  dplyr::select(-name, -month_abb) %>% #To remove "name" and "month_abb" columns so that we do not get any "NA" when we pivot_wider()
  pivot_wider(names_from = varname,
              values_from = value) %>%
  # Rounding to one decimal point
  mutate(across(c(3:75), ~round(., 1) )) #"mutate(across(c(3:75), ~round(., 1) ))": To round all columns except year and site to 1 decimal place #across() function has 2 arguments: the 1st argument "c(3:75)" is to select the position of columns on which the rounding will be applied; the 2nd argument "~round(., 1) " is to indicate the decimal place to be rounded for; "." is used to represent all those selected columns i.e., we are saying that round each of the selected columns to 1 decimal places #alternatively: mutate(across(c(3:ncol(.)), ~round(., 1) )) #alternatively: mutate(across(3:75), ~round(., 1) )); mutate(across(3:ncol(.), ~round(., 1) )); mutate(across(c(strength_gtex:sum_prcp.mm_Dec), ~round(., 1) ))

fe_month_sum_wide  

```
Notice how we are back at **698** rows.  

For each site-year, we have one piece of weather information for each of the weather variables (as opposed to the original Daymet data that had 365 rows per site-year).  

Let's explore our newly engineered variables.  

# EDA round 2  
Let's make a ridge plot to visualize the distribution of one variable over months.  

```{r, message=FALSE, warning=FALSE}

#install.packages("ggridges")
library(ggridges) #really powerful package to plot distributions e.g., density plot

ggplot(data = fe_month_sum,
       aes(x = mean_tmax.c,
           y = month_abb,
           fill = stat(x) #fill = stat(x): specific to "ggridges"
           )
       ) +
  geom_density_ridges_gradient(scale = 3,
                               rel_min_height = 0.01) + #"the 2nd argument is"rel_min_height = 0.01": to cut down the tails of the distribution
  scale_fill_viridis_c(option = "C") + #"viridis"scale_fill_viridis_c()": color-blind-friendly color scale #argument (option = "C") to change the color to magma option; "option = " varies from A to F
  theme(legend.position = "none") #"theme(legend.position = "none")": to remove legends

```

Now let's do that for all variables [ we will automate using map2() to conduct iteration ]

```{r}

finalplots <- fe_month_sum %>%
  pivot_longer(mean_dayl.s:sum_prcp.mm) %>%
  group_by(name) %>%
  nest() %>% #combo of "group_by()" and "nest()"
  mutate(plot = map2(data, name, #map2() takes 2 arguments: the 1st argument becomes .x, the 2nd argument becomes .y #we must use map2() with a mutate() at first for iteration #"map2(data, name" : we want to iterate over "name" for "data"
                     ~ ggplot( data = .x, # .x represent "data" in the map2() function, so we need to use data = .x [= "data" from map2() ] to feed the "data" from map2() function as the data of ggplot() #.x is the iterating column of map2() that is a place holder for the 1st argument of map2()
       aes(x = value,
           y = month_abb,
           fill = stat(x)
           )
       ) +
  geom_density_ridges_gradient(scale = 3,
                               rel_min_height = 0.01) + 
  scale_fill_viridis_c(option = "C") + 
  theme(legend.position = "none") +
  labs(x = .y) #to rename the x-axis as the variable name # .y is the placeholder for "name" i.e., variable name in map2() function
                     )) 
  
finalplots

```

```{r}
#| message: false

finalplots$plot #$plot to print all the ggplots for each variable

```

# Exporting  
```{r}

write_csv(fe_month_sum_wide,
          "../data/weather_monthsum.csv")

```

# Summary  
In this exercise, we:  
  - Imported the original **7** weather variables from Daymet  
  - Feature engineered a total of **72** secondary variables by applying a summarizing window size of **month** and a summarizing function of **mean or sum**.  
  - Explored the data distribution of the new variables.  
  - Exported to file to be used in subsequent exercises.




  
